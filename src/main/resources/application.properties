spring.application.name=rag-chat-bot
# Spring Boot Server Port
server.port=8080

# Spring AI Ollama Configuration
spring.ai.ollama.base-url=http://localhost:11434
spring.ai.ollama.chat.options.model=llama3:latest
# Optional: Set temperature for response creativity (0.0 to 1.0)
# spring.ai.ollama.chat.options.temperature=0.7

# To enable streaming (if you want to implement it in the UI)
# spring.ai.ollama.chat.options.stream=true

# Spring AI Logging (useful for debugging)
spring.ai.log-prompt=true
spring.ai.log-completion=true

# Placeholder for RAG data loading (will be used in AppConfig or a separate component)
# For loading documents from the 'data' directory
rag.data.path=classpath:data/*.txt

# Uncomment and configure if you use a specific vector store for RAG
# Example for a simple in-memory vector store:
# spring.ai.vectorstore.simple.initialize-schema=trueevant (0.0 to 1.0)